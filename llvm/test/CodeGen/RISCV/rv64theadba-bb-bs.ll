; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv64  -mattr=+xtheadba -mattr=+xtheadbb -mattr=+xtheadbs < %s | FileCheck %s -check-prefix=THEADC64



define i64 @addsl_i64(i64 %a, i64 %b) {
; CHECK-LABEL: addsl_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    slli a0, a0, 4
; CHECK-NEXT:    add a0, a1, a0
; CHECK-NEXT:    ret
; THEADC64-LABEL: addsl_i64:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    addsl a0, a1, a0, 3
; THEADC64-NEXT:    ret
  %shl = shl i64 %a, 3
  %and = add i64 %b, %shl
  ret i64 %and
}


define i64 @addsl_i64_1(i64 %a, i64 %b) {
; CHECK-LABEL: addsl_i64_1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addsl a0, a0, a1, 1
; CHECK-NEXT:    ret
; THEADC64-LABEL: addsl_i64_1:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    addsl a0, a0, a1, 1
; THEADC64-NEXT:    ret
  %add = add i64 %a, %b
  %add_two = add i64 %add, %b
  ret i64 %add_two
}

define i64 @addsl_i64_2(i64 %a, i64 %b){
; CHECK-LABEL: addsl_i64_2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addsl a0, a0, a1, 2
; CHECK-NEXT:    ret
; THEADC64-LABEL: addsl_i64_2:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    addsl a0, a0, a1, 2
; THEADC64-NEXT:    ret
  %shl = shl i64 %b, 1
  %add = add i64 %a, %shl
  %add_two = add i64 %add, %shl
  ret i64 %add_two
}


define i64 @addsl_i64_3(i64 %a, i64 %b){
; CHECK-LABEL: addsl_i64_3:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addsl a0, a0, a1, 3
; CHECK-NEXT:    ret
; THEADC64-LABEL: addsl_i64_3:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    addsl a0, a0, a1, 3
; THEADC64-NEXT:    ret
  %shl = shl i64 %b, 2
  %add = add i64 %a, %shl
  %add_two = add i64 %add, %shl
  ret i64 %add_two
}


define i64 @ext_i64_32(i32 %a){
; CHECK-LABEL: ext_i64_32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sext.w a0, a0
; CHECK-NEXT:    ret
; THEADC64-LABEL: ext_i64_32:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    ext a0, a0, 31, 0
; THEADC64-NEXT:    ret
  %sext32 = sext i32 %a to i64
  ret i64 %sext32
}

define i64 @ext_i64_16(i16 %a){
; CHECK-LABEL: ext_i64_16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    slli a0, a0, 48
; CHECK-NEXT:    srai a0, a0, 48
; CHECK-NEXT:    ret
; THEADC64-LABEL: ext_i64_16:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    ext a0, a0, 15, 0
; THEADC64-NEXT:    ret
  %sext16 = sext i16 %a to i64
  ret i64 %sext16
}

define i64 @ext_i64_8(i8 %a){
; CHECK-LABEL: ext_i64_8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    slli a0, a0, 56
; CHECK-NEXT:    srai a0, a0, 56
; CHECK-NEXT:    ret
; THEADC64-LABEL: ext_i64_8:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    ext a0, a0, 7, 0
; THEADC64-NEXT:    ret
  %sext8 = sext i8 %a to i64
  ret i64 %sext8
}

define i64 @ext_i64_1(i1 %a){
; CHECK-LABEL: ext_i64_1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    extu a0, a0, 0, 0
; CHECK-NEXT:    neg a0, a0
; CHECK-NEXT:    ret
; THEADC64-LABEL: ext_i64_1:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    ext a0, a0, 0, 0
; THEADC64-NEXT:    ret
  %sext1 = sext i1 %a to i64
  ret i64 %sext1
}


define i64 @extu_i64_32(i64 %a){
; CHECK-LABEL: extu_i64_32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    extu a0, a0, 31, 0
; CHECK-NEXT:    ret
; THEADC64-LABEL: extu_i64_32:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    extu a0, a0, 31, 0
; THEADC64-NEXT:    ret
  %and32 = and i64 %a, 4294967295
  ret i64 %and32
}

define i64 @extu_i64_16(i64 %a){
; CHECK-LABEL: extu_i64_16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    extu a0, a0, 15, 0
; CHECK-NEXT:    ret
; THEADC64-LABEL: extu_i64_16:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    extu a0, a0, 15, 0
; THEADC64-NEXT:    ret
  %and16 = and i64 %a, 65535
  ret i64 %and16
}

define i64 @extu_i64_8(i64 %a){
; CHECK-LABEL: extu_i64_8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    extu a0, a0, 7, 0
; CHECK-NEXT:    ret
; THEADC64-LABEL: extu_i64_8:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    extu a0, a0, 7, 0
; THEADC64-NEXT:    ret
  %and8 = and i64 %a, 255
  ret i64 %and8
}

define i64 @extu_i64_1(i64 %a){
; CHECK-LABEL: extu_i64_1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    extu a0, a0, 0, 0
; CHECK-NEXT:    ret
; THEADC64-LABEL: extu_i64_1:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    extu a0, a0, 0, 0
; THEADC64-NEXT:    ret
  %and1 = and i64 %a, 1
  ret i64 %and1
}


define i64 @ctlz_i64(i64 %a){
; CHECK-LABEL: ctlz_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    srli a1, a0, 1
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 2
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 4
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 8
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 16
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 32
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    not a0, a0
; CHECK-NEXT:    lui a1, %hi(.LCPI12_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI12_0)(a1)
; CHECK-NEXT:    lui a2, %hi(.LCPI12_1)
; CHECK-NEXT:    ld a2, %lo(.LCPI12_1)(a2)
; CHECK-NEXT:    srli a3, a0, 1
; CHECK-NEXT:    and a1, a3, a1
; CHECK-NEXT:    sub a0, a0, a1
; CHECK-NEXT:    and a1, a0, a2
; CHECK-NEXT:    srli a0, a0, 2
; CHECK-NEXT:    and a0, a0, a2
; CHECK-NEXT:    lui a2, %hi(.LCPI12_2)
; CHECK-NEXT:    ld a2, %lo(.LCPI12_2)(a2)
; CHECK-NEXT:    add a0, a1, a0
; CHECK-NEXT:    srli a1, a0, 4
; CHECK-NEXT:    add a0, a0, a1
; CHECK-NEXT:    and a0, a0, a2
; CHECK-NEXT:    lui a1, %hi(.LCPI12_3)
; CHECK-NEXT:    ld a1, %lo(.LCPI12_3)(a1)
; CHECK-NEXT:    call __muldi3@plt
; CHECK-NEXT:    srli a0, a0, 56
; CHECK-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
; THEADC64-LABEL: ctlz_i64:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    ff1 a0, a0
; THEADC64-NEXT:    ret
  %ctlz = call i64 @llvm.ctlz.i64(i64 %a, i1 1)
  ret i64 %ctlz
}

declare i64 @llvm.ctlz.i64(i64, i1)

define i64 @ctlz_i64_neg(i64 %a){
; CHECK-LABEL: ctlz_i64_neg:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    not a0, a0
; CHECK-NEXT:    srli a1, a0, 1
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 2
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 4
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 8
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 16
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a1, a0, 32
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    not a0, a0
; CHECK-NEXT:    lui a1, %hi(.LCPI13_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI13_0)(a1)
; CHECK-NEXT:    lui a2, %hi(.LCPI13_1)
; CHECK-NEXT:    ld a2, %lo(.LCPI13_1)(a2)
; CHECK-NEXT:    srli a3, a0, 1
; CHECK-NEXT:    and a1, a3, a1
; CHECK-NEXT:    sub a0, a0, a1
; CHECK-NEXT:    and a1, a0, a2
; CHECK-NEXT:    srli a0, a0, 2
; CHECK-NEXT:    and a0, a0, a2
; CHECK-NEXT:    lui a2, %hi(.LCPI13_2)
; CHECK-NEXT:    ld a2, %lo(.LCPI13_2)(a2)
; CHECK-NEXT:    add a0, a1, a0
; CHECK-NEXT:    srli a1, a0, 4
; CHECK-NEXT:    add a0, a0, a1
; CHECK-NEXT:    and a0, a0, a2
; CHECK-NEXT:    lui a1, %hi(.LCPI13_3)
; CHECK-NEXT:    ld a1, %lo(.LCPI13_3)(a1)
; CHECK-NEXT:    call __muldi3@plt
; CHECK-NEXT:    srli a0, a0, 56
; CHECK-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
; THEADC64-LABEL: ctlz_i64_neg:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    ff0 a0, a0
; THEADC64-NEXT:    ret
  %xor = xor i64 %a, -1
  %ctlz = call i64 @llvm.ctlz.i64(i64 %xor, i1 1)
  ret i64 %ctlz
}

declare i64 @llvm.bswap.i64(i64 )

define i64 @rev_i64(i64 %a){
; CHECK-LABEL: rev_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srli a1, a0, 24
; CHECK-NEXT:    lui a2, 4080
; CHECK-NEXT:    and a1, a1, a2
; CHECK-NEXT:    srli a2, a0, 8
; CHECK-NEXT:    li a3, 255
; CHECK-NEXT:    slli a4, a3, 24
; CHECK-NEXT:    and a2, a2, a4
; CHECK-NEXT:    or a1, a2, a1
; CHECK-NEXT:    srli a2, a0, 40
; CHECK-NEXT:    lui a4, 16
; CHECK-NEXT:    addiw a4, a4, -256
; CHECK-NEXT:    and a2, a2, a4
; CHECK-NEXT:    srli a4, a0, 56
; CHECK-NEXT:    or a2, a2, a4
; CHECK-NEXT:    or a1, a1, a2
; CHECK-NEXT:    slli a2, a0, 24
; CHECK-NEXT:    slli a4, a3, 40
; CHECK-NEXT:    and a2, a2, a4
; CHECK-NEXT:    srliw a4, a0, 24
; CHECK-NEXT:    slli a4, a4, 32
; CHECK-NEXT:    or a2, a2, a4
; CHECK-NEXT:    slli a4, a0, 40
; CHECK-NEXT:    slli a3, a3, 48
; CHECK-NEXT:    and a3, a4, a3
; CHECK-NEXT:    slli a0, a0, 56
; CHECK-NEXT:    or a0, a0, a3
; CHECK-NEXT:    or a0, a0, a2
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    ret
; THEADC64-LABEL: rev_i64:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    rev a0, a0
; THEADC64-NEXT:    ret
  %bswap = call i64 @llvm.bswap.i64(i64 %a)
  ret i64 %bswap
}

;; FIXME
; check second parameter is imm6 must be a number here
; or just a number in the lshr without a parameter?
define i64 @tst_i64(i64 %a){
; CHECK-LABEL: tst_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    slli a0, a0, 57
; CHECK-NEXT:    srli a0, a0, 63
; CHECK-NEXT:    ret
; THEADC64-LABEL: tst_i64:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    tst a0, a0, 33
; THEADC64-NEXT:    ret
  %srl = lshr i64 %a, 33
  %and = and i64 %srl, 1
  ret i64 %and
}

define i64 @revw_i64(i64 %a){
; CHECK-LABEL: revw_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    slli a1, a0, 24
; CHECK-NEXT:    li a2, 255
; CHECK-NEXT:    slli a3, a2, 40
; CHECK-NEXT:    and a1, a1, a3
; CHECK-NEXT:    srliw a3, a0, 24
; CHECK-NEXT:    slli a3, a3, 32
; CHECK-NEXT:    or a1, a1, a3
; CHECK-NEXT:    slli a3, a0, 40
; CHECK-NEXT:    slli a2, a2, 48
; CHECK-NEXT:    and a2, a3, a2
; CHECK-NEXT:    slli a0, a0, 56
; CHECK-NEXT:    or a0, a0, a2
; CHECK-NEXT:    or a0, a0, a1
; CHECK-NEXT:    srli a0, a0, 32
; CHECK-NEXT:    ret
; THEADC64-LABEL: revw_i64:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    rev a0, a0
; THEADC64-NEXT:    srli a0, a0, 32
; THEADC64-NEXT:    ret
  %bswap = call i64 @llvm.bswap.i64(i64 %a)
  %srl = lshr i64 %bswap, 32
  ret i64 %srl
}
declare i64 @llvm.fshr.i64(i64 %a, i64 %b, i64 %c)
declare i64 @llvm.fshl.i64(i64 , i64 , i64 )

define i64 @rotr_i64_imm6(i64 %a){
; THEADC64-LABEL: rotr_i64_imm6:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    srri a0, a0, 59
; THEADC64-NEXT:    ret
  %rotr = call i64 @llvm.fshr.i64(i64 %a, i64 %a, i64 59)
  ret i64 %rotr
}

define i64 @rotl_i64_imm6(i64 %a){
; THEADC64-LABEL: rotl_i64_imm6:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    srri a0, a0, 5
; THEADC64-NEXT:    ret
  %rotl = call i64 @llvm.fshl.i64(i64 %a, i64 %a, i64 59)
  ret i64 %rotl
}


define i64 @rotr_i64_imm5(i64 %a){
; THEADC64-LABEL: rotr_i64_imm5:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    srri a0, a0, 31
; THEADC64-NEXT:    ret
  %rotr = call i64 @llvm.fshr.i64(i64 %a, i64 %a, i64 31)
  ret i64 %rotr
}

define i64 @rotl_i64_imm5(i64 %a){
; THEADC64-LABEL: rotl_i64_imm5:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    srri a0, a0, 33
; THEADC64-NEXT:    ret
  %rotl = call i64 @llvm.fshl.i64(i64 %a, i64 %a, i64 31)
  ret i64 %rotl
}



define i64 @rotl_i64_gpr(i64 %a, i64 %b){
; CHECK-LABEL: rotl_i64_gpr:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sll a2, a0, a1
; CHECK-NEXT:    neg a1, a1
; CHECK-NEXT:    srl a0, a0, a1
; CHECK-NEXT:    or a0, a2, a0
; CHECK-NEXT:    ret
; THEADC64-LABEL: rotl_i64_gpr:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    sll a2, a0, a1
; THEADC64-NEXT:    sub a1, 64, a1
; THEADC64-NEXT:    srl a0, a0, a1
; THEADC64-NEXT:    or a0, a2, a0
; THEADC64-NEXT:    ret
  %rotl = tail call i64 @llvm.fshl.i64(i64 %a, i64 %a, i64 %b)
  ret i64 %rotl
}

define signext i64 @rotr_i64_gpr(i64 %a, i64 %b){
; CHECK-LABEL: rotr_i64_gpr:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sll a2, a0, a1
; CHECK-NEXT:    neg a1, a1
; CHECK-NEXT:    srl a0, a0, a1
; CHECK-NEXT:    or a0, a2, a0
; CHECK-NEXT:    ret
; THEADC64-LABEL: rotr_i64_gpr:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    srl a2, a0, a1
; THEADC64-NEXT:    sub a1, 64, a1
; THEADC64-NEXT:    sll a0, a0, a1
; THEADC64-NEXT:    or a0, a2, a0
; THEADC64-NEXT:    ret
  %rotl = tail call i64 @llvm.fshr.i64(i64 %a, i64 %a, i64 %b)
  ret i64 %rotl
}

;; FIXME
declare i32 @llvm.fshr.i32(i32 , i32, i32)
define signext i32 @rorw(i32 %a, i32 %b){
; THEADC64-LABEL: rorw:
; THEADC64:       # %bb.0:
; THEADC64-NEXT:    srlw a2, a0, a1
; THEADC64-NEXT:    negw a1, a1
; THEADC64-NEXT:    sllw a0, a0, a1
; THEADC64-NEXT:    or a0, a2, a0
; THEADC64-NEXT:    ret
  %rorw = call i32 @llvm.fshr.i32(i32 %a, i32 %a, i32 %b)
  ret i32 %rorw
}


